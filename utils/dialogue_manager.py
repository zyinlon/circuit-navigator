from typing import Dict, List, Any, Optional
import uuid
import pandas as pd
import re
import json
import config
import random

class DialogueState:
    def __init__(self, session_id: str):
        self.session_id = session_id
        self.current_query = ""
        self.keywords = []
        self.current_results = None  # DataFrame
        self.all_search_results = None  # æ‰€æœ‰æœç´¢ç»“æœï¼ˆåˆå§‹æœç´¢ï¼Œæœªç­›é€‰ï¼‰
        self.conversation_history = []
        self.current_question = None  # å½“å‰é—®é¢˜ä¿¡æ¯
        self.available_options = []
        self.previous_questions = []  # è®°å½•ä¹‹å‰çš„é—®é¢˜å’Œé€‰æ‹©
        self.filters_applied = []  # å·²åº”ç”¨çš„ç­›é€‰æ¡ä»¶
        self.retry_count = 0  # é—®é¢˜è®¾è®¡é‡è¯•æ¬¡æ•°
        self.state_stack = []  # ç”¨äºæ”¯æŒå›é€€çš„çŠ¶æ€æ ˆ
        self.analysis_start_index = 0  # å½“å‰åˆ†æç»“æœçš„èµ·å§‹ç´¢å¼•
        self.in_guidance_process = False  # æ˜¯å¦åœ¨å¼•å¯¼è¿‡ç¨‹ä¸­
        
    def add_question(self, question_data: Dict, user_choice: str = None):
        """è®°å½•é—®é¢˜å’Œç”¨æˆ·é€‰æ‹©"""
        record = {
            'question': question_data.get('question', ''),
            'options': question_data.get('options', []),
            'filter_field': question_data.get('filter_field', ''),
            'filter_logic': question_data.get('filter_logic', ''),
            'user_choice': user_choice
        }
        self.previous_questions.append(record)
        
    def add_filter(self, filter_info: Dict):
        """è®°å½•ç­›é€‰æ¡ä»¶"""
        self.filters_applied.append(filter_info)
        
    def reset_retry_count(self):
        """é‡ç½®é‡è¯•è®¡æ•°"""
        self.retry_count = 0
        
    def save_state(self):
        """ä¿å­˜å½“å‰çŠ¶æ€åˆ°æ ˆä¸­"""
        state_snapshot = {
            'current_query': self.current_query,
            'keywords': self.keywords.copy(),
            'current_results': self.current_results.copy() if self.current_results is not None else None,
            'all_search_results': self.all_search_results.copy() if self.all_search_results is not None else None,
            'previous_questions': self.previous_questions.copy(),
            'filters_applied': self.filters_applied.copy(),
            'current_question': self.current_question.copy() if self.current_question else None,
            'available_options': self.available_options.copy(),
            'analysis_start_index': self.analysis_start_index,
            'in_guidance_process': self.in_guidance_process,
            'conversation_history': self.conversation_history.copy()  # ä¿å­˜å¯¹è¯å†å²
        }
        self.state_stack.append(state_snapshot)
        # é™åˆ¶æ ˆå¤§å°ï¼Œé˜²æ­¢å†…å­˜æ³„æ¼
        if len(self.state_stack) > 10:
            self.state_stack.pop(0)
            
    def restore_state(self):
        """ä»æ ˆä¸­æ¢å¤ä¸Šä¸€ä¸ªçŠ¶æ€"""
        if self.state_stack:
            last_state = self.state_stack.pop()
            self.current_query = last_state['current_query']
            self.keywords = last_state['keywords']
            self.current_results = last_state['current_results']
            self.all_search_results = last_state['all_search_results']
            self.previous_questions = last_state['previous_questions']
            self.filters_applied = last_state['filters_applied']
            self.current_question = last_state['current_question']
            self.available_options = last_state['available_options']
            self.analysis_start_index = last_state['analysis_start_index']
            self.in_guidance_process = last_state['in_guidance_process']
            self.conversation_history = last_state['conversation_history']  # æ¢å¤å¯¹è¯å†å²
            return True
        return False
        
    def clear(self):
        """æ¸…ç©ºæ‰€æœ‰çŠ¶æ€"""
        self.current_query = ""
        self.keywords = []
        self.current_results = None
        self.all_search_results = None
        self.current_question = None
        self.available_options = []
        self.previous_questions = []
        self.filters_applied = []
        self.retry_count = 0
        self.state_stack = []
        self.analysis_start_index = 0
        self.in_guidance_process = False
        # ä¿ç•™æ¬¢è¿æ¶ˆæ¯çš„å†å²
        if self.conversation_history:
            self.conversation_history = [self.conversation_history[0]] if self.conversation_history[0].get('role') == 'assistant' else []

class DialogueManager:
    def __init__(self, data_loader, retriever, llm_client):
        self.data_loader = data_loader
        self.retriever = retriever
        self.llm_client = llm_client
        self.sessions = {}
    
    def get_session(self, session_id: str) -> DialogueState:
        if session_id not in self.sessions:
            self.sessions[session_id] = DialogueState(session_id)
        return self.sessions[session_id]
    
    def reset_session(self, session_id: str):
        if session_id in self.sessions:
            # æ¸…ç©ºä¼šè¯çŠ¶æ€
            self.sessions[session_id].clear()
    
    def process_query(self, session_id: str, user_input: str) -> Dict:
        """å¤„ç†ç”¨æˆ·æŸ¥è¯¢ - ä¸»å…¥å£ç‚¹"""
        session = self.get_session(session_id)
        
        # æ£€æŸ¥ç‰¹æ®ŠæŒ‡ä»¤
        if user_input == "/back":
            return self._handle_back_intent(session)
        elif user_input == "/reset":
            return self._handle_reset_intent(session, session_id)
        
        # è®°å½•å¯¹è¯å†å²
        session.conversation_history.append({
            'role': 'user',
            'content': user_input
        })
        
        # æ„å›¾è¯†åˆ« - åªå¤„ç†æœç´¢ç›¸å…³æ„å›¾
        intent_result = self._recognize_intent_for_search(session, user_input)
        intent = intent_result.get('intent', 'unknown')
        
        print(f"ğŸ” æ„å›¾è¯†åˆ«ç»“æœ: {intent}")
        print(f"æ„å›¾è¯¦æƒ…: {intent_result}")
        
        # æ ¹æ®æ„å›¾å¤„ç†
        if intent == 'new_search':
            # æ–°æœç´¢è¯·æ±‚
            return self._handle_new_search_intent(session, session_id, user_input, intent_result)
            
        elif intent == 'provide_clue':
            # æä¾›çº¿ç´¢/è¡¥å……ä¿¡æ¯
            return self._handle_clue_intent(session, user_input, intent_result)
            
        elif intent == 'other':
            # ä¸ç”µè·¯å›¾æœç´¢æ— å…³çš„è¾“å…¥
            return self._handle_other_intent(session, user_input)
            
        else:
            # æœªçŸ¥æ„å›¾ï¼ŒæŒ‰å…¶ä»–å¤„ç†
            return self._handle_other_intent(session, user_input)
    
    def _recognize_intent_for_search(self, session: DialogueState, user_input: str) -> Dict:
        """
        è¯†åˆ«ç”¨æˆ·æ„å›¾ - åªè¯†åˆ«æœç´¢ç›¸å…³æ„å›¾
        resetå’Œbackåªèƒ½é€šè¿‡æŒ‰é’®è§¦å‘ï¼Œoption_selectionåªèƒ½é€šè¿‡ç‚¹å‡»é€‰é¡¹è§¦å‘
        """
        # ä½¿ç”¨å¤§æ¨¡å‹è¿›è¡Œæ„å›¾è¯†åˆ«
        return self._recognize_intent_with_llm(session, user_input)
    
    def _recognize_intent_with_llm(self, session: DialogueState, user_input: str) -> Dict:
        """ä½¿ç”¨å¤§æ¨¡å‹è¯†åˆ«æ„å›¾ - åªè¯†åˆ«æœç´¢ç›¸å…³æ„å›¾"""
        
        # å‡†å¤‡ä¸Šä¸‹æ–‡ä¿¡æ¯
        context = {
            'current_query': session.current_query,
            'has_current_question': bool(session.current_question),
            'current_question': session.current_question.get('question', '') if session.current_question else '',
            'available_options': session.available_options,
            'previous_questions_count': len(session.previous_questions),
            'filters_applied_count': len(session.filters_applied)
        }
        
        prompt = f"""
# ç”µè·¯å›¾æœç´¢åŠ©æ‰‹æ„å›¾è¯†åˆ«

## ç”¨æˆ·è¾“å…¥
"{user_input}"

## å½“å‰å¯¹è¯ä¸Šä¸‹æ–‡
- å½“å‰æœç´¢ä¸»é¢˜: {context['current_query']}
- æ˜¯å¦æœ‰è¿›è¡Œä¸­çš„é—®é¢˜: {'æ˜¯' if context['has_current_question'] else 'å¦'}
{'- å½“å‰é—®é¢˜: ' + context['current_question'] if context['current_question'] else ''}
{'- å½“å‰é€‰é¡¹: ' + ', '.join(context['available_options']) if context['available_options'] else ''}
- å·²è¿›è¡Œçš„é—®é¢˜è½®æ•°: {context['previous_questions_count']}
- å·²åº”ç”¨çš„ç­›é€‰æ¡ä»¶: {context['filters_applied_count']}

## æ„å›¾åˆ†ç±»ï¼ˆåªè¯†åˆ«ä¸ç”µè·¯å›¾æœç´¢ç›¸å…³çš„æ„å›¾ï¼‰
1. **æ–°æœç´¢è¯·æ±‚ (new_search)** - ç”¨æˆ·æå‡ºäº†ä¸€ä¸ªå…¨æ–°çš„ç”µè·¯å›¾æœç´¢éœ€æ±‚
2. **æä¾›çº¿ç´¢ (provide_clue)** - ç”¨æˆ·åœ¨ç°æœ‰æœç´¢åŸºç¡€ä¸Šæä¾›äº†é¢å¤–ä¿¡æ¯æ¥ç¼©å°èŒƒå›´
3. **å…¶ä»– (other)** - ä¸ç”µè·¯å›¾æœç´¢æ— å…³çš„è¾“å…¥ï¼ŒåŒ…æ‹¬é—®å€™ã€é—²èŠç­‰

**æ³¨æ„**ï¼šé€‰é¡¹é€‰æ‹©ã€è¿”å›ä¸Šä¸€æ­¥ã€é‡ç½®å¯¹è¯åªèƒ½é€šè¿‡æŒ‰é’®è§¦å‘ï¼Œä¸åœ¨æ­¤è¯†åˆ«

## åˆ†æè¦ç‚¹
- å¦‚æœç”¨æˆ·æè¿°äº†ä¸€ä¸ªå…¨æ–°çš„ç”µè·¯å›¾éœ€æ±‚ï¼Œå¯èƒ½æ˜¯æ–°æœç´¢æ„å›¾
- å¦‚æœç”¨æˆ·åœ¨ç°æœ‰æœç´¢åŸºç¡€ä¸Šæä¾›ä¿¡æ¯ï¼Œå¯èƒ½æ˜¯æä¾›çº¿ç´¢
- **å¦‚æœç”¨æˆ·è¾“å…¥ä¸ç”µè·¯å›¾æœç´¢å®Œå…¨æ— å…³ï¼Œè¿”å›"other"**

## ç”µè·¯å›¾æœç´¢ç›¸å…³å…³é”®è¯å‚è€ƒ
- ç”µè·¯å›¾ã€ç”µè·¯ã€å›¾çº¸ã€æ¥çº¿å›¾ã€åŸç†å›¾ã€é’ˆè„šã€çº¿è·¯å›¾
- è½¦å‹å“ç‰Œï¼šä¸œé£ã€ä¸‰ä¸€ã€å¾å·¥ã€çº¢å²©ã€è§£æ”¾ã€é‡æ±½
- ç³»ç»Ÿéƒ¨ä»¶ï¼šä»ªè¡¨ã€å‘åŠ¨æœºã€åº•ç›˜ã€ç”µæ°”ã€ECUã€BCMã€ä¿é™©ä¸ã€ç»§ç”µå™¨
- æŸ¥è¯¢åŠ¨è¯ï¼šæ‰¾ã€éœ€è¦ã€æŸ¥ã€æœç´¢ã€å®šä½

## è¾“å‡ºæ ¼å¼
è¯·è¿”å›JSONæ ¼å¼ï¼š
{{
    "intent": "æ„å›¾ç±»å‹",
    "confidence": "high/medium/low",
    "reasoning": "åˆ¤æ–­ç†ç”±",
    "additional_info": {{  // æ ¹æ®æ„å›¾çš„é™„åŠ ä¿¡æ¯
        "clue_keywords": [],  // å¦‚æœæ˜¯æä¾›çº¿ç´¢ï¼Œæå–çš„å…³é”®è¯
        "new_query": ""       // å¦‚æœæ˜¯æ–°æœç´¢ï¼Œæå–çš„æŸ¥è¯¢å†…å®¹
    }}
}}

ç°åœ¨è¯·åˆ†æç”¨æˆ·è¾“å…¥å¹¶è¿”å›æ„å›¾è¯†åˆ«ç»“æœï¼š
"""
        
        try:
            import openai
            
            response = openai.ChatCompletion.create(
                model=config.Config.LLM_MODEL,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ„å›¾è¯†åˆ«ä¸“å®¶ï¼Œè¯·å‡†ç¡®åˆ†æç”¨æˆ·çš„æ„å›¾ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                max_tokens=800
            )
            
            content = response.choices[0].message.content.strip()
            
            # æ¸…ç†JSON
            if content.startswith('```json'):
                content = content[7:-3]
            elif content.startswith('```'):
                content = content[3:-3]
            
            result = json.loads(content)
            return result
            
        except Exception as e:
            print(f"æ„å›¾è¯†åˆ«å¤±è´¥: {e}")
            # é™çº§åˆ°è§„åˆ™åŒ¹é…
            return self._fallback_intent_recognition(session, user_input)
    
    def _fallback_intent_recognition(self, session: DialogueState, user_input: str) -> Dict:
        """é™çº§æ„å›¾è¯†åˆ«ï¼šåŸºäºè§„åˆ™"""
        
        # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯æ˜ç¡®çš„ç”µè·¯å›¾æœç´¢æ„å›¾
        circuit_keywords = [
            'ç”µè·¯å›¾', 'ç”µè·¯', 'å›¾çº¸', 'æ¥çº¿å›¾', 'åŸç†å›¾', 'é’ˆè„š', 'çº¿è·¯å›¾',
            'ä¸œé£', 'ä¸‰ä¸€', 'å¾å·¥', 'çº¢å²©', 'è§£æ”¾', 'é‡æ±½', 'ä»ªè¡¨', 'å‘åŠ¨æœº',
            'åº•ç›˜', 'ç”µæ°”', 'ECU', 'BCM', 'ä¿é™©ä¸', 'ç»§ç”µå™¨', 'æ‰¾', 'éœ€è¦',
            'æŸ¥', 'æœç´¢', 'å®šä½'
        ]
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ç”µè·¯å›¾æœç´¢ç›¸å…³å…³é”®è¯
        has_circuit_keyword = any(keyword in user_input for keyword in circuit_keywords)
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç”µè·¯å›¾ç›¸å…³çš„æ–°æŸ¥è¯¢
        if has_circuit_keyword:
            # åˆ¤æ–­æ˜¯å¦æ˜¯å…¨æ–°çš„æŸ¥è¯¢ï¼ˆæ²¡æœ‰å½“å‰æŸ¥è¯¢ï¼Œæˆ–è€…ä¸å½“å‰æŸ¥è¯¢æ˜æ˜¾ä¸åŒï¼‰
            if not session.current_query or self._is_significantly_different(session.current_query, user_input):
                return {
                    'intent': 'new_search',
                    'confidence': 'medium',
                    'reasoning': 'ç”¨æˆ·æå‡ºäº†æ–°çš„ç”µè·¯å›¾æœç´¢éœ€æ±‚',
                    'additional_info': {
                        'new_query': user_input
                    }
                }
            else:
                # ç°æœ‰æœç´¢çš„è¡¥å……
                return {
                    'intent': 'provide_clue',
                    'confidence': 'medium',
                    'reasoning': 'ç”¨æˆ·æä¾›äº†é¢å¤–çš„æœç´¢çº¿ç´¢',
                    'additional_info': {
                        'clue_keywords': [user_input]
                    }
                }
        
        # é»˜è®¤ï¼šå…¶ä»–ï¼ˆä¸ç”µè·¯å›¾æœç´¢æ— å…³ï¼‰
        return {
            'intent': 'other',
            'confidence': 'high',
            'reasoning': 'ç”¨æˆ·è¾“å…¥ä¸ç”µè·¯å›¾æœç´¢æ— å…³',
            'additional_info': {}
        }
    
    def _is_significantly_different(self, old_query: str, new_query: str) -> bool:
        """åˆ¤æ–­ä¸¤ä¸ªæŸ¥è¯¢æ˜¯å¦æ˜¾è‘—ä¸åŒ"""
        import re
        
        old_words = set(re.findall(r'[\u4e00-\u9fffA-Za-z0-9]+', old_query.lower()))
        new_words = set(re.findall(r'[\u4e00-\u9fffA-Za-z0-9]+', new_query.lower()))
        
        # è®¡ç®—Jaccardç›¸ä¼¼åº¦
        intersection = len(old_words & new_words)
        union = len(old_words | new_words)
        
        if union == 0:
            return True
        
        similarity = intersection / union
        return similarity < 0.3
    
    def _handle_other_intent(self, session: DialogueState, user_input: str) -> Dict:
        """å¤„ç†ä¸ç”µè·¯å›¾æœç´¢æ— å…³çš„è¾“å…¥"""
        # å‹å¥½å›å¤ä¸€å¥ï¼Œå¹¶å¼•å¯¼å›ç”µè·¯å›¾æœç´¢
        friendly_responses = [
            "æ‚¨å¥½ï¼æˆ‘æ˜¯è½¦è¾†ç”µè·¯å›¾å¯¼èˆªåŠ©æ‰‹ï¼Œä¸»è¦å¸®åŠ©æ‚¨æŸ¥æ‰¾è½¦è¾†ç”µè·¯å›¾æ–‡æ¡£ã€‚å¦‚æœæ‚¨éœ€è¦æœç´¢ç”µè·¯å›¾ï¼Œè¯·å‘Šè¯‰æˆ‘è½¦å‹ã€ç³»ç»Ÿæˆ–éƒ¨ä»¶åç§°ã€‚",
            "æˆ‘ä¸“æ³¨äºè½¦è¾†ç”µè·¯å›¾æœç´¢æœåŠ¡ã€‚è¯·å‘Šè¯‰æˆ‘æ‚¨éœ€è¦æŸ¥æ‰¾çš„ç”µè·¯å›¾ä¿¡æ¯ï¼Œä¾‹å¦‚ï¼š'ä¸œé£å¤©é¾™çš„ä»ªè¡¨å›¾'æˆ–'ä¸‰ä¸€æŒ–æ˜æœºçš„ç”µè·¯å›¾'ã€‚",
            "æˆ‘æ˜¯ç”µè·¯å›¾æœç´¢åŠ©æ‰‹ï¼Œå¯ä»¥å¸®æ‚¨å¿«é€Ÿå®šä½è½¦è¾†ç”µè·¯å›¾ã€‚è¯·è¾“å…¥æ‚¨çš„æœç´¢éœ€æ±‚ï¼Œä¾‹å¦‚ï¼š'å¾å·¥XE135Gçš„é’ˆè„šå®šä¹‰'æˆ–'çº¢å²©æ°ç‹®ä¿é™©ä¸å›¾çº¸'ã€‚",
            "æ¬¢è¿ä½¿ç”¨è½¦è¾†ç”µè·¯å›¾å¯¼èˆªåŠ©æ‰‹ï¼æˆ‘å¯ä»¥å¸®æ‚¨æŸ¥æ‰¾å„ç§è½¦è¾†ç”µè·¯å›¾ã€‚è¯·æè¿°æ‚¨çš„éœ€æ±‚ï¼Œæ¯”å¦‚è½¦å‹å’Œéœ€è¦çš„ç”µè·¯å›¾ç±»å‹ã€‚"
        ]
        
        response_content = random.choice(friendly_responses)
        
        # å¦‚æœæœ‰å½“å‰æœç´¢ä¸Šä¸‹æ–‡ï¼Œå¯ä»¥æä¸€ä¸‹
        if session.current_query:
            response_content += f"\n\nï¼ˆæ‚¨å½“å‰æ­£åœ¨æœç´¢ï¼š{session.current_query}ï¼‰"
        
        response = {
            'type': 'message',
            'content': response_content
        }
        
        session.conversation_history.append({
            'role': 'assistant',
            'content': response.get('content', '')
        })
        
        return response
    
    def _handle_reset_intent(self, session: DialogueState, session_id: str) -> Dict:
        """å¤„ç†é‡ç½®æ„å›¾ - æ¸…ç©ºæ‰€æœ‰çŠ¶æ€"""
        # æ¸…ç©ºä¼šè¯çŠ¶æ€
        session.clear()
        
        response = {
            'type': 'reset',
            'content': 'âœ… å¯¹è¯å·²é‡ç½®ï¼Œæ‚¨å¯ä»¥å¼€å§‹æ–°çš„æœç´¢ã€‚'
        }
        
        return response
    
    def _handle_back_intent(self, session: DialogueState) -> Dict:
        """å¤„ç†è¿”å›ä¸Šä¸€æ­¥æ„å›¾"""
        if session.restore_state():
            # æˆåŠŸæ¢å¤çŠ¶æ€
            if session.current_question:
                # è¿”å›åˆ°é—®é¢˜çŠ¶æ€
                response = {
                    'type': 'question',
                    'content': f"âœ… å·²è¿”å›ä¸Šä¸€æ­¥ã€‚\n\n{session.current_question.get('analysis', '')}\n\n{session.current_question.get('question', '')}",
                    'options': session.available_options,
                    'filter_field': session.current_question.get('filter_field', 'å±‚çº§è·¯å¾„'),
                    'filter_logic': session.current_question.get('filter_logic', 'åŒ…å«'),
                    'has_results': False
                }
            elif session.current_results is not None and not session.current_results.empty:
                # è¿”å›åˆ°ç»“æœçŠ¶æ€ï¼Œé‡æ–°å¤„ç†ç»“æœ
                return self._handle_search_results(session, session.current_query, session.current_results)
            else:
                response = {
                    'type': 'message',
                    'content': 'âœ… å·²è¿”å›ä¸Šä¸€æ­¥ï¼Œè¯·ç»§ç»­æ‚¨çš„æœç´¢ã€‚'
                }
        else:
            # æ— æ³•è¿”å›
            response = {
                'type': 'message',
                'content': 'âŒ å·²ç»æ˜¯ç¬¬ä¸€æ­¥ï¼Œæ— æ³•è¿”å›ã€‚'
            }
        
        return response
    
    def _handle_new_search_intent(self, session: DialogueState, session_id: str, user_input: str, intent_result: Dict) -> Dict:
        """å¤„ç†æ–°æœç´¢æ„å›¾"""
        # è·å–æ–°æŸ¥è¯¢å†…å®¹
        new_query = intent_result.get('additional_info', {}).get('new_query', user_input)
        
        # ä¿å­˜å½“å‰çŠ¶æ€ä»¥ä¾¿å›é€€
        session.save_state()
        
        # æ‰§è¡Œæ–°æœç´¢
        session.current_query = new_query
        session.keywords = self.llm_client.extract_keywords(new_query)
        
        # æ‰§è¡Œæœç´¢
        session.current_results = self.retriever.search(session.keywords)
        session.all_search_results = session.current_results.copy() if session.current_results is not None else None
        
        # å¤„ç†æœç´¢ç»“æœ
        return self._handle_search_results(session, new_query, session.current_results)
    
    def _handle_clue_intent(self, session: DialogueState, user_input: str, intent_result: Dict) -> Dict:
        """å¤„ç†æä¾›çº¿ç´¢æ„å›¾"""
        # ä¿å­˜å½“å‰çŠ¶æ€ä»¥ä¾¿å›é€€
        session.save_state()
        
        # å¦‚æœæ²¡æœ‰åˆå§‹æœç´¢ç»“æœï¼Œå…ˆè¿›è¡Œæœç´¢
        if session.all_search_results is None or session.all_search_results.empty:
            # å°†çº¿ç´¢ä½œä¸ºæ–°æŸ¥è¯¢
            combined_query = user_input
            session.current_query = combined_query
            session.keywords = self.llm_client.extract_keywords(combined_query)
            session.current_results = self.retriever.search(session.keywords)
            session.all_search_results = session.current_results.copy() if session.current_results is not None else None
        else:
            # åœ¨åˆå§‹æœç´¢ç»“æœä¸­åº”ç”¨çº¿ç´¢
            clue_keywords = intent_result.get('additional_info', {}).get('clue_keywords', [user_input])
            
            # åœ¨åˆå§‹æœç´¢ç»“æœä¸­åº”ç”¨çº¿ç´¢ç­›é€‰
            filtered_results = session.all_search_results.copy()
            for keyword in clue_keywords:
                if keyword:
                    # åŒæ—¶åœ¨ä¸¤ä¸ªå­—æ®µä¸­æœç´¢
                    filename_mask = filtered_results['å…³è”æ–‡ä»¶åç§°'].str.contains(keyword, case=False, na=False)
                    path_mask = filtered_results['å±‚çº§è·¯å¾„'].str.contains(keyword, case=False, na=False)
                    combined_mask = filename_mask | path_mask
                    filtered_results = filtered_results[combined_mask]
            
            session.current_results = filtered_results
            session.current_query = f"{session.current_query} {user_input}".strip()
        
        # å¤„ç†æœç´¢ç»“æœ
        return self._handle_search_results(session, session.current_query, session.current_results)
    
    def _handle_search_results(self, session: DialogueState, query: str, results: pd.DataFrame) -> Dict:
        """å¤„ç†æœç´¢ç»“æœ"""
        # æ³¨æ„ï¼šè¿™é‡Œä¸å†ä¿å­˜çŠ¶æ€ï¼Œç”±è°ƒç”¨è€…è´Ÿè´£ä¿å­˜çŠ¶æ€
        
        if results is None or results.empty:
            response = {
                'type': 'message',
                'content': 'ğŸ” æŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„ç”µè·¯å›¾ã€‚\n\nå»ºè®®ï¼š\n1. ä½¿ç”¨æ›´å…·ä½“çš„è½¦å‹æˆ–ç³»ç»Ÿåç§°\n2. æ£€æŸ¥å…³é”®è¯æ˜¯å¦æœ‰è¯¯\n3. å°è¯•ä¸åŒçš„è¡¨è¿°æ–¹å¼'
            }
        else:
            total_results = len(results)
            
            # å‘Šè¯‰ç”¨æˆ·æ€»ç»“æœæ•°å’Œå‰5ä¸ªç»“æœ
            top5_results = self.retriever.format_results_for_display(results.head(5))
            message = f"ğŸ” ä¸ºæ‚¨æ‰¾åˆ° {total_results} ä¸ªç›¸å…³ç»“æœã€‚ä»¥ä¸‹æ˜¯å‰ 5 ä¸ªç»“æœï¼š\n\n"
            
            for i, result in enumerate(top5_results, 1):
                message += f"{i}. **ID:** {result['ID']} - **æ–‡ä»¶åç§°:** {result['å…³è”æ–‡ä»¶åç§°']}\n"
            
            # æ ¹æ®ç»“æœæ•°é‡å†³å®šä¸‹ä¸€æ­¥
            if total_results <= config.Config.MAX_RESULTS_DISPLAY:
                # ç›´æ¥æ˜¾ç¤ºæ‰€æœ‰ç»“æœ
                formatted_results = self.retriever.format_results_for_display(results)
                response_text = self.llm_client.format_final_results(formatted_results, query)
                
                response = {
                    'type': 'results',
                    'content': response_text,
                    'results': formatted_results,
                    'has_results': True,
                    'results_count': len(formatted_results)
                }
            else:
                # ç»“æœå¤ªå¤šï¼Œå¼€å§‹å¼•å¯¼è¿‡ç¨‹
                session.in_guidance_process = True
                session.analysis_start_index = 0
                return self._start_guidance_process(session, query, results)
        
        session.conversation_history.append({
            'role': 'assistant',
            'content': response.get('content', '')
        })
        
        return response
    
    def _start_guidance_process(self, session: DialogueState, query: str, results: pd.DataFrame) -> Dict:
        """å¼€å§‹å¼•å¯¼è¿‡ç¨‹"""
        total_results = len(results)
        start_index = session.analysis_start_index
        end_index = min(start_index + config.Config.MAX_RESULTS_ANALYSIS, total_results)
        
        # è·å–å½“å‰æ‰¹æ¬¡çš„ç»“æœ
        current_batch = results.iloc[start_index:end_index]
        remaining_count = total_results - end_index
        
        # æ ¼å¼åŒ–å½“å‰æ‰¹æ¬¡ç»“æœ
        formatted_batch = self.retriever.format_results_for_display(current_batch)
        
        # ä½¿ç”¨å¤§æ¨¡å‹è®¾è®¡é—®é¢˜
        question_data = self.llm_client.design_question_from_results(
            query,
            formatted_batch,
            session.previous_questions
        )
        
        # å‡†å¤‡é€‰é¡¹
        options = question_data.get('options', [])
        
        # å¦‚æœæœ‰å‰©ä½™ç»“æœï¼Œæ·»åŠ "å…¶ä»–"é€‰é¡¹
        if remaining_count > 0:
            options.append(f"å…¶ä»–ï¼ˆè¿˜æœ‰{remaining_count}ä¸ªç»“æœï¼‰")
        
        # é™åˆ¶é€‰é¡¹æ•°é‡
        options = options[:config.Config.MAX_OPTIONS_DISPLAY]
        
        # æ›´æ–°ä¼šè¯çŠ¶æ€
        session.current_question = question_data
        session.available_options = options
        
        # æ„å»ºå“åº”æ¶ˆæ¯
        analysis = question_data.get('analysis', '')
        question = question_data.get('question', '')
        
        # æ·»åŠ å½“å‰æ‰¹æ¬¡ä¿¡æ¯
        batch_info = f"\n\nğŸ“Š **å½“å‰åˆ†ææ‰¹æ¬¡ä¿¡æ¯**\n- æ­£åœ¨åˆ†æç¬¬ {start_index+1}-{end_index} ä¸ªç»“æœï¼ˆå…± {total_results} ä¸ªï¼‰"
        if remaining_count > 0:
            batch_info += f"\n- åç»­è¿˜æœ‰ {remaining_count} ä¸ªç»“æœå¾…åˆ†æ"
        
        response_content = f"{analysis}{batch_info}\n\n{question}"
        
        response = {
            'type': 'question',
            'content': response_content,
            'options': options,
            'filter_field': question_data.get('filter_field', 'å±‚çº§è·¯å¾„'),
            'filter_logic': question_data.get('filter_logic', 'åŒ…å«'),
            'has_results': False
        }
        
        session.conversation_history.append({
            'role': 'assistant',
            'content': response.get('content', '')
        })
        
        return response
    
    def _handle_option_selection(self, session: DialogueState, selection: str) -> Dict:
        """å¤„ç†ç”¨æˆ·é€‰æ‹©çš„é€‰é¡¹ - åªèƒ½é€šè¿‡ç‚¹å‡»é€‰é¡¹è§¦å‘"""
        if not session.current_question:
            return {'type': 'message', 'content': 'è¯·å…ˆæå‡ºæœç´¢éœ€æ±‚ã€‚'}
        
        # ä¿å­˜çŠ¶æ€ä»¥ä¾¿å›é€€
        session.save_state()
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯"å…¶ä»–"é€‰é¡¹
        if "å…¶ä»–" in selection:
            # æ›´æ–°åˆ†æèµ·å§‹ç´¢å¼•
            session.analysis_start_index += config.Config.MAX_RESULTS_ANALYSIS
            
            # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰ç»“æœ
            if session.analysis_start_index < len(session.current_results):
                # ç»§ç»­å¼•å¯¼è¿‡ç¨‹
                return self._start_guidance_process(session, session.current_query, session.current_results)
            else:
                # æ²¡æœ‰æ›´å¤šç»“æœäº†
                response = {
                    'type': 'message',
                    'content': 'âŒ å·²ç»æ²¡æœ‰æ›´å¤šç»“æœäº†ï¼Œè¯·å°è¯•å…¶ä»–æœç´¢æ¡ä»¶ã€‚'
                }
        else:
            # åº”ç”¨ç­›é€‰
            filter_field = session.current_question.get('filter_field', 'å±‚çº§è·¯å¾„')
            filter_logic = session.current_question.get('filter_logic', 'åŒ…å«')
            
            # è®°å½•åŸå§‹ç»“æœæ•°é‡
            original_count = len(session.current_results)
            
            # ç­›é€‰ç»“æœ
            filtered_results = self.data_loader.filter_by_selection(
                session.current_results,
                selection,
                filter_field,
                filter_logic
            )
            
            print(f"ç­›é€‰ç»“æœï¼š{original_count} -> {len(filtered_results)} è¡Œ")
            
            # æ›´æ–°å½“å‰ç»“æœ
            session.current_results = filtered_results
            
            # è®°å½•é—®é¢˜å’Œé€‰æ‹©
            session.add_question(session.current_question, selection)
            
            # é‡ç½®é—®é¢˜çŠ¶æ€
            session.current_question = None
            session.available_options = []
            
            # æ£€æŸ¥ç»“æœæ•°é‡
            if session.current_results.empty:
                # æä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
                response = {
                    'type': 'message',
                    'content': f'âŒ æ ¹æ®æ‚¨é€‰æ‹©çš„"{selection}"ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³ç”µè·¯å›¾ã€‚\n\nå¯èƒ½çš„åŸå› ï¼š\n1. é€‰é¡¹æ–‡æœ¬ä¸å®é™…æ•°æ®ä¸åŒ¹é…\n2. æ•°æ®ä¸­å¯èƒ½ä½¿ç”¨ä¸åŒçš„è¡¨è¿°\n\nå»ºè®®ï¼š\n1. å°è¯•æ›´ç®€æ´çš„è¡¨è¿°ï¼ˆå¦‚"ä»ªè¡¨ç”µè·¯å›¾"è€Œä¸æ˜¯"å®Œæ•´çš„ä»ªè¡¨ç”µè·¯å›¾"ï¼‰\n2. ä½¿ç”¨"è¿”å›ä¸Šä¸€æ­¥"é€‰æ‹©å…¶ä»–é€‰é¡¹\n3. é‡æ–°æè¿°æ‚¨çš„å…·ä½“éœ€æ±‚'
                }
            else:
                # ç»§ç»­å¤„ç†ç»“æœ
                return self._handle_search_results(session, session.current_query, session.current_results)
        
        session.conversation_history.append({
            'role': 'assistant',
            'content': response.get('content', '')
        })
        
        return response