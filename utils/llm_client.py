import json
import openai
from typing import List, Dict, Any
import config
import re

class DeepSeekClient:
    def __init__(self):
        openai.api_key = config.Config.LLM_API_KEY
        openai.api_base = config.Config.LLM_BASE_URL
        self.chat_model = config.Config.LLM_MODEL
        self.reasoner_model = config.Config.LLM_REASONER_MODEL
    
    def extract_keywords(self, user_query: str) -> List[str]:
        """ä½¿ç”¨å¤§æ¨¡å‹åˆ†è¯ï¼Œæå–å…³é”®è¯ï¼ˆç§»é™¤'ç”µè·¯å›¾'å’Œ'å›¾'ï¼‰"""
        prompt = f"""
è¯·ä»ç”¨æˆ·æŸ¥è¯¢ä¸­æå–å…³é”®è¯ã€‚ç”¨æˆ·æŸ¥è¯¢æ˜¯å…³äºè½¦è¾†ç”µè·¯å›¾æœç´¢çš„ã€‚

è¦æ±‚ï¼š
1. ç§»é™¤"ç”µè·¯å›¾"å’Œ"å›¾"è¿™ä¸¤ä¸ªè¯ï¼ˆå› ä¸ºå¤ªå¸¸è§ä¸”æ•°æ®ä¸­è¡¨è¾¾ä¸ä¸€è‡´ï¼‰
2. æå–å…¶ä»–æœ‰æ„ä¹‰çš„è¯æˆ–çŸ­è¯­
3. ä¸è¦åˆå¹¶è¯ï¼Œä¿æŒåŸæ ·
4. ä¿ç•™å…¶ä»–ä¸“ä¸šæœ¯è¯­å¦‚"ä¾›ç”µ"ã€"æ¨¡å—"ã€"ECU"ç­‰

ç¤ºä¾‹ï¼š
ç”¨æˆ·æŸ¥è¯¢ï¼š"ä¸œé£å¤©é¾™ä»ªè¡¨ç”µè·¯å›¾"
è¾“å‡ºï¼š{{"keywords": ["ä¸œé£", "å¤©é¾™", "ä»ªè¡¨"]}}

ç”¨æˆ·æŸ¥è¯¢ï¼š"æˆ‘è¦æ‰¾ä¸‰ä¸€SY215C9çš„æ¶²å‹ç”µè„‘æ¿"
è¾“å‡ºï¼š{{"keywords": ["ä¸‰ä¸€", "SY215C9", "æ¶²å‹", "ç”µè„‘æ¿"]}}

ç”¨æˆ·æŸ¥è¯¢ï¼š"ä¾›ç”µæ¨¡å—ç›¸å…³å›¾çº¸"
è¾“å‡ºï¼š{{"keywords": ["ä¾›ç”µ", "æ¨¡å—"]}}

ç”¨æˆ·æŸ¥è¯¢ï¼š"è§£æ”¾J6çš„æ•´è½¦ç”µè·¯å›¾"
è¾“å‡ºï¼š{{"keywords": ["è§£æ”¾", "J6", "æ•´è½¦"]}}

ç°åœ¨è¯·å¤„ç†è¿™ä¸ªæŸ¥è¯¢ï¼š
ç”¨æˆ·æŸ¥è¯¢ï¼š"{user_query}"

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼Œæ ¼å¼ä¸ºï¼š{{"keywords": ["å…³é”®è¯1", "å…³é”®è¯2", ...]}}
"""
        
        try:
            response = openai.ChatCompletion.create(
                model=self.chat_model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå…³é”®è¯æå–åŠ©æ‰‹ï¼Œè¯·å‡†ç¡®æå–ç”¨æˆ·æŸ¥è¯¢ä¸­çš„å…³é”®è¯ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                max_tokens=500
            )
            
            content = response.choices[0].message.content.strip()
            
            # æ¸…ç†JSON
            if content.startswith('```json'):
                content = content[7:-3]
            elif content.startswith('```'):
                content = content[3:-3]
            
            result = json.loads(content)
            keywords = result.get('keywords', [])
            
            # ç¡®ä¿éƒ½æ˜¯å­—ç¬¦ä¸²ä¸”éç©º
            keywords = [str(kw).strip() for kw in keywords if str(kw).strip()]
            
            print(f"æå–åˆ°çš„å…³é”®è¯ï¼ˆå·²ç§»é™¤'ç”µè·¯å›¾'å’Œ'å›¾'ï¼‰: {keywords}")
            return keywords
            
        except Exception as e:
            print(f"å¤§æ¨¡å‹åˆ†è¯å¤±è´¥: {e}")
            # ä¸è¿›è¡Œé™çº§ï¼Œè¿”å›ç©ºåˆ—è¡¨
            return []
    
    def fuzzy_correct_query(self, user_query: str) -> Dict[str, Any]:
        """ä½¿ç”¨å¤§æ¨¡å‹å¯¹ç”¨æˆ·è¾“å…¥è¿›è¡Œæ¨¡ç³ŠåŒ¹é…ä¿®æ­£"""
        prompt = f"""
# è½¦è¾†ç”µè·¯å›¾æŸ¥è¯¢æ¨¡ç³ŠåŒ¹é…ä¿®æ­£

## ç”¨æˆ·åŸå§‹æŸ¥è¯¢
"{user_query}"

## ä»»åŠ¡è¯´æ˜
è¯·å¯¹ç”¨æˆ·çš„ç”µè·¯å›¾æœç´¢æŸ¥è¯¢è¿›è¡Œæ™ºèƒ½ä¿®æ­£ã€‚ç”¨æˆ·å¯èƒ½è¾“å…¥äº†é”™åˆ«å­—ã€ç®€å†™ã€å£è¯­åŒ–è¡¨è¾¾æˆ–ä¸è§„èŒƒè¡¨è¿°ï¼Œéœ€è¦ä¿®æ­£ä¸ºæ ‡å‡†åŒ–çš„è½¦è¾†ç”µè·¯å›¾æœç´¢æœ¯è¯­ã€‚

## å¸¸è§çš„éœ€è¦ä¿®æ­£çš„æƒ…å†µ
1. **å“ç‰Œå‹å·é”™åˆ«å­—**ï¼š
   - "å°å¿ª" â†’ "å°æ¾"ï¼ˆå·¥ç¨‹æœºæ¢°å“ç‰Œï¼‰
   - "é‡æ±½è±ªæ±‰" â†’ "é‡æ±½è±ªç€š"ï¼ˆé‡æ±½è½¦å‹ï¼‰
   - "åº†é¾„" â†’ "åº†é“ƒ"ï¼ˆæ±½è½¦å“ç‰Œï¼‰
   - "å¾å·¥æŒ–æœº" â†’ "å¾å·¥æŒ–æ˜æœº"

2. **æ•°å­—è¯¯å†™**ï¼š
   - "2ooo" â†’ "2000"
   - "25o" â†’ "250"
   - "ä¸‰ä¸€215" â†’ "ä¸‰ä¸€SY215" æˆ– "ä¸‰ä¸€215"

3. **å£è¯­åŒ–/ä¸å®Œæ•´è¡¨è¾¾**ï¼š
   - "ä¾›ç”µçš„å›¾" â†’ "ä¾›ç”µç”µè·¯å›¾"
   - "å‘åŠ¨æœºçº¿è·¯" â†’ "å‘åŠ¨æœºç”µè·¯å›¾"
   - "ä»ªè¡¨ç›˜çš„å›¾" â†’ "ä»ªè¡¨ç”µè·¯å›¾"

4. **å‹å·è§„æ ¼è¡¥å…¨**ï¼š
   - "XE135" â†’ "XE135G"ï¼ˆå¾å·¥æŒ–æ˜æœºï¼‰
   - "å¤©é¾™D" â†’ "å¤©é¾™D320"ï¼ˆä¸œé£è½¦å‹ï¼‰
   - "SY215" â†’ "SY215C9"ï¼ˆä¸‰ä¸€æŒ–æ˜æœºï¼‰

## ä¿®æ­£åŸåˆ™
1. **å‡†ç¡®æ€§ä¼˜å…ˆ**ï¼šä¸ç¡®å®šçš„ä¸è¦ä¹±æ”¹
2. **ä¿æŒåŸæ„**ï¼šåªä¿®æ­£æ˜æ˜¾çš„é”™è¯¯ï¼Œä¸æ”¹å˜ç”¨æˆ·æ„å›¾
3. **ä¸“ä¸šè§„èŒƒ**ï¼šä¿®æ­£ä¸ºè¡Œä¸šé€šç”¨æœ¯è¯­
4. **è¡¥å……å®Œæ•´**ï¼šè¡¥å……å¸¸è§çš„å‹å·åç¼€

## å·²çŸ¥å“ç‰Œå‹å·å‚è€ƒ
- æŒ–æ˜æœºï¼šå°æ¾PC200ã€PC300ã€PC360ï¼›ä¸‰ä¸€SY215ã€SY235ã€SY285ï¼›å¾å·¥XE135ã€XE150ã€XE210
- å¡è½¦ï¼šä¸œé£å¤©é¾™ã€å¤©é”¦ï¼›é‡æ±½è±ªç€šã€è±ªæ²ƒï¼›è§£æ”¾J6ã€J7ï¼›çº¢å²©æ°ç‹®ã€æ°è±¹
- å…¶ä»–ï¼šåº†é“ƒã€æ±Ÿé“ƒã€ç¦ç”°

## è¾“å‡ºæ ¼å¼
è¯·è¿”å›JSONæ ¼å¼ï¼š
{{
    "original_query": "åŸå§‹æŸ¥è¯¢",
    "corrected_query": "ä¿®æ­£åçš„æŸ¥è¯¢",
    "explanation": "ä¿®æ­£è¯´æ˜ï¼Œè§£é‡Šåšäº†å“ªäº›ä¿®æ”¹",
    "confidence": "high/medium/low"  // ä¿®æ­£ç½®ä¿¡åº¦
}}

ç°åœ¨è¯·åˆ†æå’Œä¿®æ­£ç”¨æˆ·æŸ¥è¯¢ï¼š
"""
        
        try:
            response = openai.ChatCompletion.create(
                model=self.chat_model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªè½¦è¾†ç”µè·¯å›¾æœç´¢ä¸“å®¶ï¼Œæ“…é•¿è¯†åˆ«å’Œä¿®æ­£ä¸è§„èŒƒçš„æŸ¥è¯¢è¡¨è¿°ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                max_tokens=800
            )
            
            content = response.choices[0].message.content.strip()
            
            # æ¸…ç†JSON
            if content.startswith('```json'):
                content = content[7:-3]
            elif content.startswith('```'):
                content = content[3:-3]
            
            result = json.loads(content)
            return result
            
        except Exception as e:
            print(f"æ¨¡ç³ŠåŒ¹é…ä¿®æ­£å¤±è´¥: {e}")
            # è¿”å›åŸå§‹æŸ¥è¯¢ä½œä¸ºå¤‡é€‰
            return {
                "original_query": user_query,
                "corrected_query": user_query,
                "explanation": "ä¿®æ­£å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æŸ¥è¯¢",
                "confidence": "low"
            }
    
    def design_question_from_results(self, 
                                   user_query: str, 
                                   results: List[Dict],
                                   previous_questions: List[Dict] = None) -> Dict:
        """æ ¹æ®æœç´¢ç»“æœè®¾è®¡é€‰æ‹©é¢˜ - ä½¿ç”¨reasoneræ¨¡å‹è¿›è¡Œæ¨ç†"""
        
        # å‡†å¤‡ç»“æœä¿¡æ¯
        results_info = []
        for result in results:
            results_info.append({
                'ID': result['ID'],
                'å±‚çº§è·¯å¾„': result['å±‚çº§è·¯å¾„'],
                'å…³è”æ–‡ä»¶åç§°': result['å…³è”æ–‡ä»¶åç§°']
            })
        
        # åˆ†æå½“å‰æ‰¹æ¬¡ç»“æœçš„ç‰¹å¾
        batch_count = len(results)
        
        # ä»ç»“æœä¸­æå–å¯èƒ½çš„é€‰é¡¹
        extracted_options = self._extract_potential_options(results)
        
        prompt = f"""
# è½¦è¾†ç”µè·¯å›¾æœç´¢é—®é¢˜è®¾è®¡

## ç”¨æˆ·æŸ¥è¯¢åˆ†æ
ç”¨æˆ·æŸ¥è¯¢ï¼š"{user_query}"

## å½“å‰æ‰¹æ¬¡ç»“æœåˆ†æ
æ­£åœ¨åˆ†æ {batch_count} ä¸ªç»“æœï¼Œè®¾è®¡é—®é¢˜å¸®åŠ©ç”¨æˆ·è¿›ä¸€æ­¥ç­›é€‰ã€‚

## ç»“æœæ ·æœ¬
{json.dumps(results_info, ensure_ascii=False, indent=2)}

## æå–çš„æ½œåœ¨é€‰é¡¹ï¼ˆåŸºäºå®é™…æ•°æ®ï¼‰
{json.dumps(extracted_options, ensure_ascii=False, indent=2)}

## è®¾è®¡ä»»åŠ¡
è¯·è®¾è®¡ä¸€ä¸ªé€‰æ‹©é¢˜æ¥å¸®åŠ©ç”¨æˆ·ç¼©å°èŒƒå›´ã€‚è¯·åŸºäºå®é™…æ•°æ®è®¾è®¡å…·ä½“çš„ã€å¯ç­›é€‰çš„é€‰é¡¹ã€‚

### å…³é”®è¦æ±‚ï¼š
1. **é€‰é¡¹å¿…é¡»å…·ä½“**ï¼šæ¯ä¸ªé€‰é¡¹åº”è¯¥æ˜¯ç”¨æˆ·å¯ä»¥ç›´æ¥é€‰æ‹©çš„å…·ä½“å€¼ï¼Œè€Œä¸æ˜¯æè¿°æ€§è¯­è¨€
2. **åŸºäºå®é™…æ•°æ®**ï¼šé€‰é¡¹åº”æ¥è‡ªæå–çš„æ½œåœ¨é€‰é¡¹æˆ–ç»“æœä¸­çš„å…·ä½“å€¼
3. **å¯ç­›é€‰æ€§**ï¼šæ¯ä¸ªé€‰é¡¹å¿…é¡»èƒ½åœ¨æŒ‡å®šå­—æ®µä¸­æ‰¾åˆ°åŒ¹é…ï¼ˆé€šè¿‡"åŒ…å«"é€»è¾‘ï¼‰
4. **ç®€æ´æ˜äº†**ï¼šé€‰é¡¹åº”è¯¥ç®€æ´ï¼Œé¿å…æ‹¬å·ä¸­çš„è§£é‡Š

### é€‰é¡¹è®¾è®¡ç¤ºä¾‹ï¼š
âŒ é”™è¯¯ç¤ºä¾‹ï¼ˆè¿‡äºæè¿°æ€§ï¼‰ï¼š
- "å®Œæ•´çš„ä»ªè¡¨ç”µè·¯å›¾ï¼ˆæ–‡ä»¶åç§°é€šå¸¸å«'ä»ªè¡¨ç”µè·¯å›¾'ï¼‰"
- "ç‰¹å®šæ§åˆ¶æ¨¡å—ï¼ˆå¦‚BCMï¼ŒVECUï¼‰çš„é’ˆè„šå®šä¹‰æ–‡æ¡£"

âœ… æ­£ç¡®ç¤ºä¾‹ï¼ˆå…·ä½“å¯ç­›é€‰ï¼‰ï¼š
- "ä»ªè¡¨ç”µè·¯å›¾"
- "é’ˆè„šå®šä¹‰"
- "ä¸œé£å¤©é¾™ä»ªè¡¨"
- "BCMé’ˆè„šå®šä¹‰"

### è¾“å‡ºæ ¼å¼ï¼š
{{
    "analysis": "å¯¹å½“å‰æ‰¹æ¬¡ç»“æœçš„åˆ†æï¼Œè¯´æ˜è®¾è®¡é—®é¢˜çš„ä¾æ®",
    "question": "ç»™ç”¨æˆ·çš„æ¸…æ™°é—®é¢˜",
    "options": ["å…·ä½“é€‰é¡¹1", "å…·ä½“é€‰é¡¹2", "å…·ä½“é€‰é¡¹3"],
    "filter_field": "å…³è”æ–‡ä»¶åç§°",  // æˆ–"å±‚çº§è·¯å¾„"
    "filter_logic": "åŒ…å«",  // ä½¿ç”¨"åŒ…å«"è€Œä¸æ˜¯"ç­‰äº"
    "design_reasoning": "è¯¦ç»†è¯´æ˜æ¯ä¸ªé€‰é¡¹çš„è®¾è®¡ä¾æ®å’Œæœ‰æ•ˆæ€§"
}}

ç°åœ¨è¯·æ ¹æ®ä¸Šé¢çš„åˆ†æè®¾è®¡é—®é¢˜ï¼š
"""
        
        try:
            response = openai.ChatCompletion.create(
                model=self.reasoner_model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç”µè·¯å›¾æœç´¢åŠ©æ‰‹ï¼Œæ“…é•¿é€šè¿‡æ•°æ®åˆ†æè®¾è®¡æœ‰æ•ˆçš„é—®é¢˜ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                max_tokens=1500
            )
            
            content = response.choices[0].message.content.strip()
            
            # æ¸…ç†JSON
            if content.startswith('```json'):
                content = content[7:-3]
            elif content.startswith('```'):
                content = content[3:-3]
            
            result = json.loads(content)
            
            # éªŒè¯å¹¶ä¼˜åŒ–é€‰é¡¹
            validated_result = self._validate_and_optimize_options(result, results)
            return validated_result
            
        except Exception as e:
            print(f"æ¨ç†æ¨¡å‹è®¾è®¡é—®é¢˜å¤±è´¥: {e}")
            # ä½¿ç”¨æå–çš„é€‰é¡¹ä½œä¸ºå¤‡é€‰
            return {
                "analysis": f"åˆ†æäº†å½“å‰ {batch_count} ä¸ªç»“æœï¼Œå‘ç°ä»¥ä¸‹ç‰¹å¾ï¼š",
                "question": "è¯·é€‰æ‹©æ‚¨éœ€è¦çš„æ–‡æ¡£ç±»å‹ï¼š",
                "options": extracted_options.get('filename_keywords', ['ä»ªè¡¨ç”µè·¯å›¾', 'é’ˆè„šå®šä¹‰'])[:5],
                "filter_field": "å…³è”æ–‡ä»¶åç§°",
                "filter_logic": "åŒ…å«",
                "design_reasoning": "åŸºäºæ–‡ä»¶åå…³é”®è¯æå–"
            }
    
    def _extract_potential_options(self, results: List[Dict]) -> Dict:
        """ä»ç»“æœä¸­æå–æ½œåœ¨çš„é€‰é¡¹"""
        if not results:
            return {"filename_keywords": [], "path_keywords": []}
        
        filename_keywords = set()
        path_keywords = set()
        
        # å¸¸è§çš„å…³é”®è¯æ¨¡å¼
        common_patterns = [
            r'ã€([^ã€‘]+)ã€‘',  # æ–¹æ‹¬å·å†…çš„å†…å®¹
            r'\[([^\]]+)\]',  # æ–¹æ‹¬å·å†…çš„å†…å®¹
            r'\(([^)]+)\)',  # åœ†æ‹¬å·å†…çš„å†…å®¹
        ]
        
        # å¸¸è§çš„å…³é”®è¯
        common_keywords = [
            'ä»ªè¡¨ç”µè·¯å›¾', 'é’ˆè„šå®šä¹‰', 'åŸç†å›¾', 'æ¥çº¿å›¾', 'ç”µè·¯åŸç†',
            'æ•´è½¦', 'ä»ªè¡¨', 'å‘åŠ¨æœº', 'åº•ç›˜', 'ç”µæ°”', 'ECU', 'BCM', 'VECU',
            'ä¿é™©ä¸', 'ç»§ç”µå™¨', 'ä¼ æ„Ÿå™¨', 'ä¸œé£', 'å¤©é¾™', 'ä¸‰ä¸€', 'å¾å·¥', 'çº¢å²©'
        ]
        
        for result in results:
            # ä»æ–‡ä»¶åä¸­æå–
            filename = result['å…³è”æ–‡ä»¶åç§°']
            
            # æå–æ¨¡å¼åŒ¹é…çš„å†…å®¹
            for pattern in common_patterns:
                matches = re.findall(pattern, filename)
                for match in matches:
                    if match and len(match) >= 2:
                        filename_keywords.add(match)
            
            # æ£€æŸ¥å¸¸è§å…³é”®è¯
            for keyword in common_keywords:
                if keyword in filename:
                    filename_keywords.add(keyword)
            
            # ä»å±‚çº§è·¯å¾„ä¸­æå–
            path = result['å±‚çº§è·¯å¾„']
            path_parts = path.split('->')
            for part in path_parts:
                part = part.strip()
                if part and len(part) > 1 and part not in ['ç”µè·¯å›¾', 'æ•´è½¦', 'èµ„æ–™']:
                    path_keywords.add(part)
        
        return {
            "filename_keywords": list(filename_keywords)[:10],  # é™åˆ¶æ•°é‡
            "path_keywords": list(path_keywords)[:10]
        }
    
    def _validate_and_optimize_options(self, question_data: Dict, results: List[Dict]) -> Dict:
        """éªŒè¯å¹¶ä¼˜åŒ–é€‰é¡¹ï¼Œç¡®ä¿æ¯ä¸ªé€‰é¡¹éƒ½èƒ½åœ¨ç»“æœä¸­æ‰¾åˆ°"""
        options = question_data.get('options', [])
        filter_field = question_data.get('filter_field', 'å…³è”æ–‡ä»¶åç§°')
        filter_logic = question_data.get('filter_logic', 'åŒ…å«')
        
        # æ¸…ç†é€‰é¡¹ï¼šç§»é™¤æ‹¬å·ä¸­çš„è§£é‡Šå’Œå¤šä½™çš„æè¿°
        cleaned_options = []
        for option in options:
            # ç§»é™¤æ‹¬å·åŠæ‹¬å·å†…çš„å†…å®¹
            cleaned = re.sub(r'ï¼ˆ[^ï¼‰]*ï¼‰', '', option)  # ä¸­æ–‡æ‹¬å·
            cleaned = re.sub(r'\([^)]*\)', '', cleaned)  # è‹±æ–‡æ‹¬å·
            cleaned = re.sub(r'\[[^\]]*\]', '', cleaned)  # æ–¹æ‹¬å·
            cleaned = re.sub(r'ã€[^ã€‘]*ã€‘', '', cleaned)  # æ–¹æ‹¬å·
            
            # ç§»é™¤å¸¸è§çš„æè¿°æ€§çŸ­è¯­
            descriptive_phrases = [
                'å®Œæ•´çš„', 'ç‰¹å®šçš„', 'ç›¸å…³', 'æ–‡æ¡£', 'æ–‡ä»¶', 'å›¾çº¸',
                'é€šå¸¸å«', 'åŒ…å«', 'å¦‚', 'ä¾‹å¦‚', 'æ¯”å¦‚'
            ]
            for phrase in descriptive_phrases:
                cleaned = cleaned.replace(phrase, '')
            
            # æ¸…ç†ç©ºæ ¼å’Œæ ‡ç‚¹
            cleaned = cleaned.strip(' ï¼Œã€ã€‚,.')
            if cleaned:
                cleaned_options.append(cleaned)
        
        # å¦‚æœæ¸…ç†åé€‰é¡¹ä¸ºç©ºï¼Œä½¿ç”¨åŸå§‹é€‰é¡¹
        if not cleaned_options:
            cleaned_options = options
        
        # éªŒè¯æ¯ä¸ªé€‰é¡¹æ˜¯å¦èƒ½åœ¨ç»“æœä¸­æ‰¾åˆ°
        valid_options = []
        for option in cleaned_options:
            found = False
            
            # é¦–å…ˆå°è¯•ç²¾ç¡®åŒ¹é…
            for result in results:
                field_value = str(result[filter_field])
                if filter_logic == "åŒ…å«" and option in field_value:
                    found = True
                    break
                elif filter_logic == "ç­‰äº" and option == field_value:
                    found = True
                    break
            
            # å¦‚æœç²¾ç¡®åŒ¹é…å¤±è´¥ï¼Œå°è¯•éƒ¨åˆ†åŒ¹é…ï¼ˆä½¿ç”¨é€‰é¡¹ä¸­çš„å…³é”®è¯ï¼‰
            if not found and len(option) > 2:
                # å°è¯•å°†é€‰é¡¹æ‹†åˆ†ä¸ºå…³é”®è¯
                keywords = re.findall(r'[\u4e00-\u9fffA-Za-z0-9]{2,}', option)
                for keyword in keywords:
                    for result in results:
                        field_value = str(result[filter_field])
                        if keyword in field_value:
                            found = True
                            valid_options.append(keyword)  # ä½¿ç”¨å…³é”®è¯ä½œä¸ºé€‰é¡¹
                            break
                    if found:
                        break
            
            # å¦‚æœæ‰¾åˆ°åŒ¹é…ï¼Œä½¿ç”¨åŸå§‹é€‰é¡¹
            if found and option not in valid_options:
                valid_options.append(option)
        
        # å¦‚æœæœ‰æ•ˆé€‰é¡¹ä¸è¶³ï¼Œä»ç»“æœä¸­æå–
        if len(valid_options) < 2:
            # ä»æ–‡ä»¶åä¸­æå–å¸¸è§å…³é”®è¯
            for result in results:
                filename = result['å…³è”æ–‡ä»¶åç§°']
                # æå–é•¿åº¦2-6çš„ä¸­æ–‡è¯
                chinese_words = re.findall(r'[\u4e00-\u9fff]{2,6}', filename)
                for word in chinese_words:
                    if word not in valid_options and len(word) >= 2:
                        valid_options.append(word)
                        if len(valid_options) >= 5:
                            break
                if len(valid_options) >= 5:
                    break
        
        # æ›´æ–°é—®é¢˜æ•°æ®
        question_data['options'] = valid_options[:5]  # é™åˆ¶æœ€å¤š5ä¸ªé€‰é¡¹
        
        # æ›´æ–°åˆ†æè¯´æ˜
        if len(valid_options) < len(options):
            original_analysis = question_data.get('analysis', '')
            question_data['analysis'] = f"{original_analysis}\n\næ³¨æ„ï¼šå·²ä¼˜åŒ–é€‰é¡¹ä»¥ç¡®ä¿å¯ç­›é€‰æ€§ã€‚"
        
        return question_data
    
    def format_final_results(self, results: List[Dict], query: str) -> str:
        """æ ¼å¼åŒ–æœ€ç»ˆç»“æœ"""
        if not results:
            return "æŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„ç”µè·¯å›¾ã€‚è¯·å°è¯•æ›´æ¢å…³é”®è¯é‡æ–°æœç´¢ã€‚"
        
        if len(results) == 1:
            result = results[0]
            return (
                f"âœ… **å·²ä¸ºæ‚¨æ‰¾åˆ°ç²¾ç¡®åŒ¹é…çš„ç”µè·¯å›¾**\n\n"
                f"ğŸ“„ **æ–‡æ¡£æ ‡é¢˜**ï¼š{result['å…³è”æ–‡ä»¶åç§°']}\n"
                f"ğŸ”¢ **æ–‡æ¡£ID**ï¼š{result['ID']}\n"
                f"ğŸ“ **åˆ†ç±»**ï¼š{result['å±‚çº§è·¯å¾„']}"
            )
        else:
            formatted = f"âœ… **ä¸ºæ‚¨æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³ç»“æœ**\n\n"
            
            for i, result in enumerate(results, 1):
                formatted += f"**ç»“æœ {i}ï¼š**\n"
                formatted += f"ğŸ“„ **æ–‡æ¡£æ ‡é¢˜**ï¼š{result['å…³è”æ–‡ä»¶åç§°']}\n"
                formatted += f"ğŸ”¢ **æ–‡æ¡£ID**ï¼š{result['ID']}\n"
                formatted += f"ğŸ“ **åˆ†ç±»**ï¼š{result['å±‚çº§è·¯å¾„']}\n"
                
                if i < len(results):
                    formatted += f"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\n"
                else:
                    formatted += "\n"
            
            return formatted